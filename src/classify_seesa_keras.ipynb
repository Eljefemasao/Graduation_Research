{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduation Research "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNISTのデータセットを利用して中間層出力検証方法の正確性を検証する(grad_cam検証)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-16-b3a9e37451be>, line 426)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-b3a9e37451be>\"\u001b[0;36m, line \u001b[0;32m426\u001b[0m\n\u001b[0;31m    url=\"/home/seimei/Graduation_Research/dataset/hare/hare_D2/image_0132.jpg\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1枚の画像に対しPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2枚の画像に対しPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2D_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seimei/usr/bin/virtualenv/tensorflow-with-gpu/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 300, 300, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 300, 300, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 150, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 150, 150, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 82944)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               42467840  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 43,642,148\n",
      "Trainable params: 43,642,148\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "3\n",
      "[[1.2099503e-09 1.6495471e-01 3.3613599e-06 8.3504188e-01]]\n",
      "Tensor(\"max_pooling2d_3/MaxPool:0\", shape=(?, 37, 37, 128), dtype=float32)\n",
      "~~~~~~\n",
      "[<keras.layers.convolutional.Conv2D object at 0x7fbe2a079908>, <keras.layers.convolutional.Conv2D object at 0x7fbe2a079a20>, <keras.layers.convolutional.Conv2D object at 0x7fbe4990e940>, <keras.layers.convolutional.Conv2D object at 0x7fbe498c2e80>, <keras.layers.convolutional.Conv2D object at 0x7fbe498dbf28>, <keras.layers.convolutional.Conv2D object at 0x7fbe49888b38>, <keras.layers.convolutional.Conv2D object at 0x7fbe498a57b8>, <keras.layers.core.Dense object at 0x7fbe4980d6d8>, <keras.layers.core.Dense object at 0x7fbe4982c438>]\n",
      "[array([[[[ 1.6533146e-03,  2.4222357e-03, -2.4028867e-03],\n",
      "         [ 1.7479003e-03,  1.0435760e-03, -5.6486884e-03],\n",
      "         [-1.5706711e-03,  4.1037393e-03, -9.2931530e-03],\n",
      "         ...,\n",
      "         [ 1.8892514e-03,  6.6311383e-03, -7.5325919e-03],\n",
      "         [ 1.1805096e-04, -3.9531616e-03, -2.5240332e-03],\n",
      "         [ 2.8991399e-03,  5.6298194e-04, -5.8081094e-03]],\n",
      "\n",
      "        [[-1.0869566e-03,  5.9190509e-03, -2.2058801e-03],\n",
      "         [-6.3521606e-03,  8.4517486e-03, -4.9898513e-03],\n",
      "         [-1.2058559e-02,  1.0822455e-02, -1.7876375e-02],\n",
      "         ...,\n",
      "         [-1.0700976e-02,  5.8036470e-03, -1.8751025e-02],\n",
      "         [-2.3369002e-03,  9.9080615e-05, -1.9797739e-02],\n",
      "         [-3.1933801e-03,  1.5509436e-03, -1.0612874e-02]],\n",
      "\n",
      "        [[ 4.9686409e-05,  3.8465322e-03, -7.0053646e-03],\n",
      "         [-5.4352283e-03,  5.0272131e-03, -9.8469295e-03],\n",
      "         [-2.2189198e-03,  8.4267370e-03, -1.4926838e-02],\n",
      "         ...,\n",
      "         [-6.4983759e-03,  4.7921045e-03, -2.0790985e-02],\n",
      "         [-7.0328107e-03,  1.5023954e-02, -2.7784007e-02],\n",
      "         [-2.9359357e-03,  1.8336847e-03, -8.4479935e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.1906936e-03,  1.2238990e-03,  7.2156859e-04],\n",
      "         [ 4.2521395e-05, -2.0948434e-03,  2.2642227e-04],\n",
      "         [ 7.5013604e-04,  1.0896381e-03, -2.2249459e-04],\n",
      "         ...,\n",
      "         [-1.4698181e-03, -1.2025832e-03, -8.2801944e-03],\n",
      "         [ 6.3455291e-04, -1.4404998e-03, -9.4727734e-03],\n",
      "         [ 3.5870457e-03,  1.4108629e-04, -3.9554429e-03]],\n",
      "\n",
      "        [[-6.3549425e-04,  1.5453638e-03,  8.0178154e-04],\n",
      "         [ 1.1651075e-03,  2.0431597e-03, -2.6142695e-03],\n",
      "         [-8.1504404e-04, -1.2861195e-03,  1.0554751e-03],\n",
      "         ...,\n",
      "         [ 6.8536325e-04,  7.1836857e-04, -2.7125606e-03],\n",
      "         [-1.2869380e-03,  2.7112698e-03, -4.3704519e-03],\n",
      "         [-1.2650343e-03,  5.5831182e-04, -1.8042130e-03]],\n",
      "\n",
      "        [[-1.5356705e-03, -2.6178261e-04,  7.6549128e-05],\n",
      "         [ 1.0742251e-03,  1.9781149e-03,  9.5957512e-05],\n",
      "         [-2.6097149e-04,  8.2753983e-04, -4.1585005e-04],\n",
      "         ...,\n",
      "         [-2.3914315e-03,  3.2521002e-03, -4.8699859e-04],\n",
      "         [-1.4073265e-03,  2.5772641e-04, -2.8567412e-03],\n",
      "         [-2.7911901e-04,  4.8395398e-04, -1.4448999e-03]]]],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import cross_validation\n",
    "import keras.callbacks\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from keras.preprocessing import image\n",
    "import keras\n",
    "\n",
    "from keras.models import load_model\n",
    "import random as rn\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import model_from_json\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input \n",
    "#https://stackoverflow.com/questions/47555829/preprocess-input-method-in-keras                                                                                                            \n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "#from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from PIL import ImageFile\n",
    "import math\n",
    "#from sklearn.datasets import fetch_mldata\n",
    "\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "from keras.layers.core import Lambda\n",
    "from keras.models import Sequential\n",
    "from tensorflow.python.framework import ops\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras \n",
    "import sys \n",
    "import cv2\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "#画像がPILでロードできない問題について\n",
    "# PILは極端に大きな画像など高速にロードできない画像はロードしないで見過ごす仕様になっている故の解決法\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# 使用するGPUの割り当てを決定する\n",
    "config = tf.ConfigProto(device_count={'GPU':0 ,'CPU':56})\n",
    "sess = tf.Session(config=config)\n",
    "keras.backend.set_session(sess)\n",
    "\n",
    "\n",
    "STANDARD_SIZE = (300, 300)\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "\n",
    "#session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)                              \n",
    "\n",
    "input_shape = (300, 300, 3)\n",
    "batch_size = 8\n",
    "epochs = 15\n",
    "num_classes = 4\n",
    "\n",
    "f_log = './logs/object_classificationAB/'\n",
    "f_model = './model/test/'\n",
    "\n",
    "\n",
    "model_filename = 'cnn_model.json'\n",
    "weights_filename = 'cnn_model_weights.hdf5'\n",
    "\n",
    "\n",
    "\n",
    "def input_data(path_train, path_test):\n",
    "\n",
    "    x = []\n",
    "\n",
    "    with open(path_train, \"r\") as f:\n",
    "        train_path_list = f.readlines()\n",
    "\n",
    "    filenames = []\n",
    "    labels = []\n",
    "    for row in train_path_list:\n",
    "        row = row.split(\" \")\n",
    "        filenames.append(row[0])\n",
    "        labels.append(int(row[1]))\n",
    "\n",
    "    for f in filenames:\n",
    "        x.append(image.img_to_array(img_to_matrix(f)))\n",
    "\n",
    "    x = np.asarray(x)\n",
    "    #正規化                                                                                                                 \n",
    "    #x /= 255\n",
    "    x = (x-np.amin(x))/(np.amax(x)-np.amin(x))\n",
    "    y = np.asarray(labels)\n",
    "    y = tf.keras.utils.to_categorical(y, num_classes)\n",
    "\n",
    "    '==============================================================='\n",
    "\n",
    "    a = []\n",
    "    \n",
    "    with open(path_test, \"r\") as f:\n",
    "        train_path_list = f.readlines()\n",
    "\n",
    "    filenames1 = []\n",
    "    labels1 = []\n",
    "    for row in train_path_list:\n",
    "        row = row.split(\" \")\n",
    "        filenames1.append(row[0])\n",
    "        labels1.append(int(row[1]))\n",
    "\n",
    "    for f in filenames1:\n",
    "        a.append(image.img_to_array(img_to_matrix(f)))\n",
    "\n",
    "    test_data = np.asarray(a)\n",
    "    # 正規化                                                                                                                \n",
    "    #test_data /= 255\n",
    "    test_data = (test_data-np.amin(test_data))/(np.amax(test_data)-np.amin(test_data))\n",
    "    test_label = np.asarray(labels1)\n",
    "    test_label = keras.utils.to_categorical(test_label, num_classes)\n",
    "\n",
    "    train_data, valid_data, train_label, valid_label = cross_validation.train_test_split(x, y, test_size=0.3)\n",
    "    test_data, valid1, test_label, valid2 = cross_validation.train_test_split(test_data, test_label, test_size=0.3)\n",
    "    \n",
    "    print(np.shape(train_data))\n",
    "    print(np.shape(train_label))\n",
    "    return train_data, test_data, train_label, test_label, valid_data, valid_label\n",
    "\n",
    "\n",
    "\n",
    "def tf_image_translate(images, tx, ty, interpolation=\"NEAREST\"):\n",
    "    # got these parameters from solving the equations for pixel translations\n",
    "    # on https://www.tensorflow.org/api_docs/python/tf/contrib/image/transform\n",
    "    translations = [1, 0, -tx, 0, 1, -ty, 0, 0]\n",
    "    return tf.contrib.image.translation(images, transforms, interpolation)\n",
    "    \n",
    "    \"\"\"\n",
    "    #augmentations\n",
    "    if is_training():\n",
    "        #color augmentations\n",
    "        image = tf.image.random_brightness(image,max_delta=63)\n",
    "        #image = tf.image.random_saturation(image, lower=0.5, upper=1.5, seed=seed2) \n",
    "        #image = tf.image.random_hue(image, max_delta=0.2, seed=seed3)\n",
    "        image = tf.image.random_contrast(image, lower=0.2, upper=1.8)\n",
    "        \n",
    "        tx = tf.random_normal(shape=[], mean=0.0, stddev=20.0, dtype=tf.float32)#正規分布によるランダム値 \n",
    "        ty = tf.random_normal(shape=[], mean=0.0, stddev=20.0, dtype=tf.float32)\n",
    "        image = tf_image_translate(image, tx=tx, ty=ty)\n",
    "        \n",
    "        degrees = tf.random_normal(shape=[], mean=0.0, stddev=5.0, dtype=tf.float32)\n",
    "        image = tf.contrib.image.rotate(image, degrees*math.pi/180, interpolation=\"BILINEAR\")\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# parse image                                                                                                               \n",
    "def img_to_matrix(filename, verbose=False):\n",
    "    img = Image.open(filename)\n",
    "    if verbose:\n",
    "        print('changing size from %s to %s' % (str(img.size), str(STANDARD_SIZE)))\n",
    "    img = img.resize(STANDARD_SIZE)\n",
    "    imgArray = np.asarray(img)\n",
    "    return imgArray  # imgArray.shape = (167 x 300 x 3)                                                                     \n",
    "\n",
    "\n",
    "    \n",
    "def target_category_loss(x, category_index, nb_classes):\n",
    "    return tf.multiply(x, KTF.one_hot([category_index], nb_classes))\n",
    "\n",
    "def target_category_loss_output_shape(input_shape):\n",
    "    return input_shape\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (KTF.sqrt(KTF.mean(KTF.square(x)) + 1e-5))\n",
    "\n",
    "def load_image(path):\n",
    "    img_path = path\n",
    "    img = image.load_img(img_path, target_size=(300, 300))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    " #   x = preprocess_input(x)\n",
    "    return x\n",
    "\n",
    "def register_gradient():\n",
    "    if \"GuidedBackProp\" not in ops._gradient_registry._registry:\n",
    "        @ops.RegisterGradient(\"GuidedBackProp\")\n",
    "        def _GuidedBackProp(op, grad):\n",
    "            dtype = op.inputs[0].dtype\n",
    "            return grad * tf.cast(grad > 0., dtype) *  tf.cast(op.inputs[0] > 0., dtype)\n",
    "\n",
    "def compile_saliency_function(model, activation_layer='conv2d_8'):\n",
    "    \"\"\"\n",
    "    category_index=1\n",
    "    nb_classes = num_classes\n",
    "    target_layer = lambda x: target_category_loss(x, category_index, nb_classes)\n",
    "    s = input_model.layers[-1].output\n",
    "    x1 = Lambda(target_layer, output_shape=target_category_loss_output_shape)(s)\n",
    "    model = keras.models.Model(input_model.layers[0].input, x1)\n",
    "    input_img = model.layers[0].input\n",
    "\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "    layer_output =layer_dict[activation_layer].output\n",
    "   #print(layer_output)\n",
    "    max_output = KTF.max(layer_output, axis=3)\n",
    "    saliency = KTF.gradients(KTF.sum(max_output), input_img)[0]\n",
    "    \"\"\"\n",
    "    input_img = model.input\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "    layer_output = layer_dict[activation_layer].output\n",
    "    max_output = K.max(layer_output, axis=3)\n",
    "    saliency = K.gradients(K.sum(max_output), input_img)[0]\n",
    "    return K.function([input_img, K.learning_phase()], [saliency])\n",
    "    \n",
    "    #return KTF.function([input_img, KTF.learning_phase()], [saliency])\n",
    "\n",
    "\n",
    "      \n",
    "def modify_backprop(model, name):\n",
    "\n",
    "    g = tf.get_default_graph()\n",
    "\n",
    "    with g.gradient_override_map({'Relu': name}):\n",
    "\n",
    "        # get layers that have an activation\n",
    "        layer_dict = [layer for layer in model.layers[1:]\n",
    "                      if hasattr(layer, 'activation')]\n",
    "        print(layer_dict)\n",
    "        # replace relu activation\n",
    "        for layer1 in layer_dict:\n",
    "            if layer1.activation == keras.activations.relu:\n",
    "                layer1.activation = tf.nn.relu\n",
    "\n",
    "        # re-instanciate a new model\n",
    "        new_model = model\n",
    "    return new_model\n",
    "\n",
    "def deprocess_image(x):\n",
    "    '''\n",
    "    Same normalization as in:\n",
    "    https://github.com/fchollet/keras/blob/master/examples/conv_filter_visualization.py\n",
    "    '''\n",
    "    if np.ndim(x) > 3:\n",
    "        x = np.squeeze(x)\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if KTF.image_dim_ordering() == 'th':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "\n",
    "        \n",
    "def grad_cam(input_model, image, category_index, layer_name):\n",
    "  \n",
    "    nb_classes = num_classes\n",
    "    target_layer = lambda x: target_category_loss(x, category_index, nb_classes)\n",
    "    x = input_model.layers[-1].output\n",
    "    x = Lambda(target_layer, output_shape=target_category_loss_output_shape)(x)\n",
    "    model = keras.models.Model(input_model.layers[0].input, x)\n",
    "\n",
    "    conv_output =model.layers[9].output #model.layers[5].output \n",
    "    print(conv_output)\n",
    "    #print(conv_output =  [l for l in input_model.layers if l.name == layer_name][0].output)\n",
    "    \n",
    "    loss = KTF.sum(model.layers[-1].output)\n",
    "    print(\"~~~~~~\")\n",
    "\n",
    "    grads = normalize(KTF.gradients(loss, conv_output)[0])\n",
    "    gradient_function = KTF.function([model.layers[0].input], [conv_output, grads])\n",
    "    output, grads_val = gradient_function([image])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
    "    #多分GAP\n",
    "    weights = np.mean(grads_val, axis = (0, 1))\n",
    "    cam = np.ones(output.shape[0 : 2], dtype = np.float32)\n",
    "\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w*(255*output[:, :, i])\n",
    "\n",
    "    cam = cv2.resize(cam, (300, 300))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    heatmap = cam / np.max(cam)\n",
    "    \n",
    "    #Return to BGR [0..255] from the preprocessed image\n",
    "    image = image[0, :]\n",
    "    image -= np.min(image)\n",
    "    image = np.minimum(image, 255)\n",
    "\n",
    "    cam1 = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "    cam = np.float32(cam1) + np.float32(255*image)\n",
    "    cam = 255 * cam / np.max(cam)\n",
    "    cv2.imwrite(\"heat.jpg\",cam1)\n",
    "    return np.uint8(cam), heatmap\n",
    "\n",
    "\n",
    "\n",
    "def check_accuracy_rate(model):\n",
    "    path_and_label_and_weather = []\n",
    "    with open(\"./path_and_label_test.txt\",\"r\") as s:\n",
    "            image_urls=s.readlines()\n",
    "    \n",
    "    for i in image_urls:\n",
    "            url_and_label=i.strip(\" \").split(\" \")\n",
    "            image_url = url_and_label[0]\n",
    "            image_label=url_and_label[1]\n",
    "            img = image.load_img(image_url, target_size=(300,300))\n",
    "            img=image.img_to_array(img)\n",
    "            img.astype(\"float32\")\n",
    "            img/=255.0\n",
    "            predictions=model.predict(np.expand_dims(img,axis=0))\n",
    "            predicted_label=np.argmax(predictions)\n",
    "            if int(predicted_label) != int(image_label):\n",
    "                t=image_url.split(\"/\")\n",
    "                count=0\n",
    "                for s in t:\n",
    "                    if s==\"dataset_valid\":\n",
    "                        name=t[count+1]\n",
    "                    count+=1\n",
    "                path_and_label_and_weather.append([image_url,name,predicted_label,int(image_label)])\n",
    "                \n",
    "                with open(\"./doc/incorrect_test_images.txt\",\"a\") as f:\n",
    "                    f.write(image_url+\"\\n\")\n",
    "\n",
    "            elif int(predicted_label) == int(image_label) :\n",
    "                if (predictions[0,predicted_label] < np.float32(\"0.7\")):\n",
    "                    with open(\"./doc/corret_test_images.txt\",\"a\") as g:\n",
    "                        g.write(image_url+\"\\n\")\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    df = pd.DataFrame(path_and_label_and_weather,columns=[\"path\",\"weater\",\"predicted_label\",\"label\"])\n",
    "    #df=df.set_index(\"weater\")\n",
    "    df.to_csv(\"./doc/incorrect_test_images.csv\")\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "def main():\n",
    "\n",
    "   # x_train, x_test, y_train, y_test, valid_data, valid_label = input_data(\"path_and_label_train.txt\",\n",
    "#                                                                              \"path_and_label_test.txt\")\n",
    "\n",
    "  #  old_session = KTF.get_session()\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        session = tf.Session('')\n",
    "        \n",
    "        KTF.set_session(session)\n",
    "        \"\"\"\n",
    "        KTF.set_learning_phase(1)#(0 = test, 1 = train) これがGrad-CAMをダメにしていた！！！　Grad-CAM使うときはコメントアウトすること\n",
    "       # saver = tf.train.import_meta_graph(\"./tmp/model.ckpt.meta\")\n",
    "        #saver.restore(session, \"./tmp/model.ckpt\")\n",
    "\n",
    "        \n",
    "        model = Sequential()                                                                                                \n",
    "        model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=input_shape, kernel_initializer=\"he_normal\", bias_initializer=\"zeros\"))                                                                         \n",
    "        model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))                                                                    \n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        #model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "        model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "        model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "        model.add(Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "        model.add(Flatten())                                                                                                \n",
    "        model.add(Dense(512, activation='relu', init='he_uniform'))          # どのようにハイパーパラメータ512を決めるのか→https://stackoverflow.com/questions/36950394/how-to-decide-the-size-of-layers-in-keras-dense-method                                                \n",
    "        #model.add(Dropout(0.5))                                                                                             \n",
    "        model.add(Dense(num_classes, activation='softmax')) # num_classes = 2値分類                                         \n",
    "    \n",
    "                                                                                                                            \n",
    " \n",
    "       # load trained model                                                                                                \n",
    "        #json_string = open(os.path.join(f_model, model_filename)).read()\n",
    "        #model = model_from_json(json_string)\n",
    "        #model.load_weights(os.path.join(f_model, weights_filename))\n",
    "        \"\"\"\n",
    "        model = load_model('./model/test/Mymodel2.h5')\n",
    "        print(model.summary())\n",
    "       \n",
    "\n",
    "        \"\"\"\n",
    "        model.compile(loss=keras.losses.categorical_crossentropy,                                                           \n",
    "                      optimizer=\"SGD\",                                                                                      \n",
    "                      metrics=['accuracy'])                                                                                 \n",
    "                                                                                                                            \n",
    "        print(model.summary())                                                                                              \n",
    "                                                                                                                            \n",
    "        # callback function                                                                                                 \n",
    "        tb_cb = keras.callbacks.TensorBoard(log_dir=f_log, histogram_freq=1)                                                \n",
    "        cbks = [tb_cb]                                                                                                      \n",
    "                                                                                                                            \n",
    "        # train                                                                                                             \n",
    "        history = model.fit(x_train, y_train,                                                                               \n",
    "                            batch_size=batch_size,                                                                          \n",
    "                            epochs=epochs,                                                                                  \n",
    "                            verbose=1,       #進行状況の表示モード                                                          \n",
    "                            callbacks=cbks,  # [plot_losses, csv_logger],                                                   \n",
    "                            validation_data=(x_test, y_test))                                                               \n",
    "        score_train = model.evaluate(x_train,y_train, verbose=1, batch_size=batch_size)                                              \n",
    "        score_test = model.evaluate(x_test, y_test, verbose=1, batch_size=batch_size)                                                \n",
    "        print('Train loss: {0}'.format(score_train[0]))                                                                     \n",
    "        print('Train accuracy: {0}'.format(score_train[1]))                                                                 \n",
    "        print('Test loss: {0}'.format(score_test[0]))                                                                       \n",
    "        print('Test accuracy: {0}'.format(score_test[1]))                                                                   \n",
    "\n",
    "       # saver = tf.train.Saver()\n",
    "        #save_path=saver.save(session, \"./tmp/model.ckpt\")\n",
    "        model.save('./model/test/Mymodel2.h5')\n",
    "        \"\"\"\n",
    "\n",
    "        #テスト画像全ての正誤を取得\n",
    "        #check_accuracy_rate(model)\n",
    "    \n",
    "#        img = image.load_img(\"/home/seimei/brush.jpg\", target_size=(300, 300))\n",
    "\n",
    "    # add for TeonsorBoard                                                                                                                                  \n",
    "\n",
    "   # KTF.set_session(old_session)\n",
    "        url=\"/home/seimei/Graduation_Research/dataset/hare/hare_D2/image_0037.jpg\"\n",
    "    #'/home/seimei/Graduation_Research/dataset/kumori/kumori_D2/image_0001.jpg'  なるほどね\n",
    "    #\"/home/seimei/Graduation_Research/dataset_valid/hare/hare_D4/image_0189.jpg\"\n",
    "    #\"/home/seimei/Graduation_Research/dataset_valid/hare/class_B5/image_0019.jpg\"\n",
    "    #\"/home/seimei/Graduation_Research/dataset_valid/hare/hare_D4/image_0024.jpg\"\n",
    "        img = image.img_to_array(img_to_matrix(url))\n",
    "        img.astype('float32')\n",
    "        img /= 255.0\n",
    "        img = np.expand_dims(img,axis=0)\n",
    "           # preprocessed_input = load_image(\"/home/seimei/image_0058_brush.jpg\")\n",
    "        predictions=model.predict(img)#np.expand_dims(img, axis=0))\n",
    "\n",
    "        \n",
    "        predicted_class= np.argmax(predictions)\n",
    "        print(predicted_class)\n",
    "        print(predictions)\n",
    "        cam, heatmap = grad_cam(model, img, predicted_class, \"conv2d_6\")\n",
    "        cv2.imwrite(\"gradcam.jpg\", cam)\n",
    "        cv2.imwrite(\"test_heatmap.jpg\", heatmap)\n",
    "        register_gradient()\n",
    "        guided_model = modify_backprop(model, 'GuidedBackProp')\n",
    "        saliency_fn = compile_saliency_function(guided_model)\n",
    "        saliency = saliency_fn([img,0])#[np.expand_dims(img, axis=0), 0])\n",
    "        print(saliency)\n",
    "        gradcam = saliency[0] * heatmap[..., np.newaxis]\n",
    "        #  print(type(gradcam))\n",
    "        cv2.imwrite(\"guided_gradcam.jpg\", deprocess_image(gradcam))\n",
    "        session.close()\n",
    "    sess.close()\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
